#========= ä¿®æ­£äº†æ­£åˆ™æœ‰é¡ºåºæ‰èƒ½è¯†åˆ«çš„bug    ===============
import requests
import time
import random
import os
import json
from bs4 import BeautifulSoup


# ========== æ ¸å¿ƒï¼šä»JSONå­—å…¸æå–id/tokenï¼ˆæ— è§†é¡ºåºï¼‰ ==========
def extract_outer_id_and_token(raw_data_str):
    """
    ä»JSONå­—å…¸ä¸­ç›´æ¥æå–idå’Œxsec_tokenï¼ˆä¸ä¾èµ–å­—æ®µé¡ºåºï¼‰
    :param raw_data_str: åŸå§‹JSONå­—ç¬¦ä¸²æ•°æ®
    :return: æå–åˆ°çš„(id, xsec_token)åˆ—è¡¨
    """
    try:
        json_data = json.loads(raw_data_str)
        data = json_data.get("data", {})
        items = data.get("items", [])

        result = []
        for item in items:
            # ç›´æ¥æŒ‰å­—æ®µåæå–ï¼Œå®Œå…¨æ— è§†é¡ºåº
            item_id = item.get("id", "")
            token = item.get("xsec_token", "")
            if item_id and token:
                result.append((item_id, token))
            # é¡ºä¾¿åˆ é™¤note_cardï¼ˆæ— éœ€å•ç‹¬å†™å‡½æ•°ï¼‰
            item.pop("note_card", None)

        print(f"âœ… æˆåŠŸæå– {len(result)} ç»„æœ‰æ•ˆid/xsec_tokenï¼ˆæ— è§†å­—æ®µé¡ºåºï¼‰")
        return result

    except json.JSONDecodeError:
        print("âŒ é”™è¯¯ï¼šåŸå§‹æ•°æ®ä¸æ˜¯åˆæ³•çš„JSONæ ¼å¼")
        return []
    except Exception as e:
        print(f"âŒ æå–id/tokenå‡ºé”™ï¼š{str(e)}")
        return []


# ========== ä¿å­˜å†…å®¹åˆ°åºåˆ—æ–‡ä»¶å¤¹ ==========
def save_content(desc_text, image_url, headers, root_data_path="data"):
    if not os.path.exists(root_data_path):
        os.makedirs(root_data_path)
        print(f"ğŸ“ æ ¹æ–‡ä»¶å¤¹ {root_data_path} ä¸å­˜åœ¨ï¼Œå·²åˆ›å»º")

    # ç”Ÿæˆåºåˆ—æ–‡ä»¶å¤¹å
    existing_folders = []
    for folder in os.listdir(root_data_path):
        folder_path = os.path.join(root_data_path, folder)
        if os.path.isdir(folder_path) and folder.startswith("data_"):
            try:
                folder_num = int(folder.split("_")[1])
                existing_folders.append(folder_num)
            except (IndexError, ValueError):
                continue

    new_folder_num = max(existing_folders) + 1 if existing_folders else 1
    new_folder_name = f"data_{new_folder_num}"
    new_folder_path = os.path.join(root_data_path, new_folder_name)

    try:
        os.makedirs(new_folder_path)
        print(f"\nğŸ“ å·²åˆ›å»ºåºåˆ—æ–‡ä»¶å¤¹ï¼š{new_folder_path}")
    except Exception as e:
        print(f"âŒ åˆ›å»ºåºåˆ—æ–‡ä»¶å¤¹å¤±è´¥ï¼š{str(e)}")
        return

    # ä¿å­˜æè¿°æ–‡æœ¬
    txt_file_path = os.path.join(new_folder_path, "description.txt")
    try:
        with open(txt_file_path, 'w', encoding='utf-8') as f:
            f.write(desc_text)
        print(f"ğŸ“ æè¿°æ–‡æœ¬å·²ä¿å­˜åˆ°ï¼š{txt_file_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æè¿°æ–‡æœ¬å¤±è´¥ï¼š{str(e)}")

    # ä¸‹è½½å›¾ç‰‡
    if not image_url:
        print("âŒ æ— å›¾ç‰‡URLï¼Œè·³è¿‡å›¾ç‰‡ä¸‹è½½")
        return

    sleep_time = random.uniform(1, 3)
    print(f"\nğŸ–¼ï¸ å‡†å¤‡è®¿é—®å›¾ç‰‡URLï¼š{image_url}")
    print(f"â³ ç­‰å¾… {sleep_time:.2f} ç§’åä¸‹è½½...")
    time.sleep(sleep_time)

    img_suffix = image_url.split(".")[-1].split("!")[0]
    if img_suffix not in ["jpg", "png", "webp", "jpeg"]:
        img_suffix = "jpg"
    img_file_name = f"image_{random.randint(1000, 9999)}.{img_suffix}"
    img_file_path = os.path.join(new_folder_path, img_file_name)

    try:
        response = requests.get(image_url, headers=headers, timeout=10, stream=True)
        if response.status_code == 200:
            with open(img_file_path, 'wb') as f:
                for chunk in response.iter_content(1024):
                    f.write(chunk)
            print(f"âœ… å›¾ç‰‡å·²ä¸‹è½½åˆ°ï¼š{img_file_path}")
        else:
            print(f"âŒ å›¾ç‰‡URLè®¿é—®å¤±è´¥ï¼çŠ¶æ€ç ï¼š{response.status_code}")
    except requests.exceptions.Timeout:
        print(f"âŒ å›¾ç‰‡URLè®¿é—®è¶…æ—¶ï¼")
    except requests.exceptions.ConnectionError:
        print(f"âŒ å›¾ç‰‡URLç½‘ç»œè¿æ¥é”™è¯¯ï¼")
    except Exception as e:
        print(f"âŒ å›¾ç‰‡ä¸‹è½½å‡ºé”™ï¼š{str(e)}")


# ========== è®¿é—®URLå¹¶æå–å†…å®¹ ==========
def insect(urls):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Referer": "https://www.xiaohongshu.com/"
    }

    if not urls:
        print("âŒ æ²¡æœ‰å¯è®¿é—®çš„URLï¼")
        return

    print("\n========== å¼€å§‹è®¿é—®å°çº¢ä¹¦URLï¼ˆæ¨¡æ‹ŸçœŸäººèŠ‚å¥ï¼‰ ==========")
    for idx, url in enumerate(urls, 1):
        sleep_time = random.uniform(2, 5)
        print(f"\nã€ç¬¬{idx}ä¸ªURLã€‘: {url}")
        print(f"â³ ç­‰å¾… {sleep_time:.2f} ç§’åè®¿é—®...")
        time.sleep(sleep_time)

        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                print(f"âœ… ç½‘é¡µè®¿é—®æˆåŠŸï¼å“åº”çŠ¶æ€ç ï¼š{response.status_code}")

                soup = BeautifulSoup(response.text, 'lxml')
                # æå–descriptionæ–‡æœ¬
                desc_tag = soup.find('meta', attrs={'name': 'description'})
                desc_text = desc_tag['content'] if (desc_tag and 'content' in desc_tag.attrs) else "æœªæå–åˆ°æè¿°æ–‡æœ¬"
                print(f"\nğŸ“„ æå–åˆ°çš„æè¿°æ–‡æœ¬ï¼š{desc_text}")

                # æå–preloadå›¾ç‰‡URL
                preload_img_tag = soup.find('link', attrs={'rel': 'preload', 'as': 'image'})
                img_url = preload_img_tag['href'] if (preload_img_tag and 'href' in preload_img_tag.attrs) else ""
                if img_url:
                    print(f"ğŸ”— æå–åˆ°çš„é¢„åŠ è½½å›¾ç‰‡URLï¼š{img_url}")
                else:
                    print(f"âŒ æœªæå–åˆ°preloadå›¾ç‰‡URL")

                save_content(desc_text, img_url, headers)

            elif response.status_code == 403:
                print(f"âŒ ç½‘é¡µè®¿é—®è¢«æ‹’ç»ï¼ˆ403ï¼‰ï¼šå»ºè®®å¢å¤§é—´éš”æˆ–æ›´æ¢UA")
            elif response.status_code == 404:
                print(f"âŒ ç½‘é¡µURLæ— æ•ˆï¼ˆ404ï¼‰ï¼š{url}")
            else:
                print(f"âŒ ç½‘é¡µè®¿é—®å¤±è´¥ï¼çŠ¶æ€ç ï¼š{response.status_code}")

        except requests.exceptions.Timeout:
            print(f"âŒ ç½‘é¡µè®¿é—®è¶…æ—¶ï¼")
        except requests.exceptions.ConnectionError:
            print(f"âŒ ç½‘é¡µç½‘ç»œè¿æ¥é”™è¯¯ï¼")
        except Exception as e:
            print(f"âŒ ç½‘é¡µè®¿é—®/è§£æå‡ºé”™ï¼š{str(e)}")


# ========== ä¸»å‡½æ•° ==========
if __name__ == "__main__":
    # 1. è¯»å–JSONæ•°æ®æ–‡ä»¶
    file_path = r"xiaohongshu_data_2.txt"
    raw_data = ""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            raw_data = f.read()
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ {file_path}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
        # æµ‹è¯•ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆæ•…æ„æ‰“ä¹±idå’Œtokené¡ºåºï¼‰
        raw_data = """
        {
            "data": {
                "items": [
                    {
                        "xsec_token": "ABoVoOTZNOT5_vDnmGeWb7XQKF7ZJzMeFTIYEL321cWrM=",
                        "model_type": "note",
                        "note_card": {...},
                        "id": "67d25423000000000901413b"
                    },
                    {
                        "model_type": "note",
                        "id": "66e98abf0000000027004b5a",
                        "xsec_token": "ABWF6ORf4h2lT2ksZbRC_22EPzQONEczamyJdmVn_T69o=",
                        "note_card": {...}
                    }
                ]
            }
        }
        """

    # 2. æå–idå’Œxsec_tokenï¼ˆæ— è§†é¡ºåºï¼‰
    result = extract_outer_id_and_token(raw_data)
    xhs_urls = []
    if result:
        print("\nâœ… æå–åˆ°çš„idå’Œxsec_tokenï¼ˆæ— è§†é¡ºåºï¼‰ï¼š")
        for idx, (item_id, xsec_token) in enumerate(result, 1):
            print(f"\nç¬¬{idx}æ¡ï¼š")
            print(f"id: {item_id}")
            print(f"xsec_token: {xsec_token}")
            xhs_url = f"https://www.xiaohongshu.com/explore/{item_id}?xsec_token={xsec_token}"
            print(f"å°çº¢ä¹¦é“¾æ¥: {xhs_url}")
            xhs_urls.append(xhs_url)
    else:
        print("âŒ æœªæå–åˆ°ä»»ä½•æ•°æ®ï¼")

    # 3. è®¿é—®URLå¹¶ä¿å­˜å†…å®¹
    insect(xhs_urls)